{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised machine learning\n",
    "\n",
    "Previously, we have taken MR images and attempt assign to them values of normal/diseased, at a whole image level (classification) or a pixel level (segmentation). But what if we don't have labels?\n",
    "\n",
    "We are going to spent this tutorial exploring how to find patterns in data using unsupervised machine learning. We'll introduce three new tools that require no labels (though we'll keep track of them to evaluate our performance):\n",
    "\n",
    "- Autoencoders: deep neural network designed minimize the \"reconstruction error\" between the input and output (which are the same)\n",
    "- K-means clustering: a way of automatically find groups of unlabelled data points in space based on distances between them\n",
    "- K-nearest neighbours: assigning a new data point a label based on its proximity to other labelled data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "train_path = 'C:/Users/jxb29/Dropbox (Partners HealthCare)/Teaching/BRATS_10_Updated/*/*.nii.gz'\n",
    "sequences = ['t1', 't2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import label, regionprops\n",
    "\n",
    "def normalize_images(channel_copy):\n",
    "        \n",
    "    label_image = label(channel_copy == 0)\n",
    "\n",
    "    largest_label, largest_area = None, 0\n",
    "    for region in regionprops(label_image):\n",
    "        if region.area > largest_area:\n",
    "            largest_area = region.area\n",
    "            largest_label = region.label\n",
    "\n",
    "    mask = label_image == largest_label     \n",
    "    masked_channel = np.ma.masked_where(mask, channel_copy)\n",
    "\n",
    "    masked_channel = masked_channel - np.mean(masked_channel)\n",
    "    masked_channel = masked_channel / np.std(masked_channel)\n",
    "    masked_channel = np.ma.getdata(masked_channel)\n",
    "    return masked_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import nibabel as nib\n",
    "from os.path import basename\n",
    "import numpy as np \n",
    "\n",
    "all_images = glob(train_path)\n",
    "slices = []\n",
    "labels = []\n",
    "\n",
    "for nifti_file in all_images:\n",
    "    \n",
    "    seq = basename(nifti_file).split('.')[0].split('_')[-1]\n",
    "    \n",
    "    if seq not in sequences:\n",
    "        continue\n",
    "    \n",
    "    # Load Nifti file, normalize it\n",
    "    vol = nib.load(nifti_file).get_data()\n",
    "    vol = normalize_images(vol)\n",
    "    \n",
    "    # Take a middle-ish section of the volume\n",
    "    halfway_point = vol.shape[2] // 2\n",
    "    sample = [vol[:,:,i] for i in range(halfway_point-20, halfway_point+20)]\n",
    "    slices.extend(sample)\n",
    "    \n",
    "    # Keep track of the labels (sequence ID: 0 == t1, 1 == t2)\n",
    "    index = sequences.index(seq)\n",
    "    index_list = [index] * 40\n",
    "    labels.extend(index_list)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 240, 240, 1)\n"
     ]
    }
   ],
   "source": [
    "# (samples: 40 * N, rows: 240, columns: 240, channels: 1)\n",
    "X = np.expand_dims(np.asarray(slices), axis=-1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_23 (Conv2D)           (None, 240, 240, 8)       80        \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 240, 240, 8)       32        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 120, 120, 8)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 120, 120, 16)      1168      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 120, 120, 16)      64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 60, 60, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 60, 60, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 60, 60, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 30, 30, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 30, 30, 32)        18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 30, 30, 32)        128       \n",
      "=================================================================\n",
      "Total params: 43,456\n",
      "Trainable params: 43,152\n",
      "Non-trainable params: 304\n",
      "_________________________________________________________________\n",
      "None\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# from models import autoencoder\n",
    "%autoreload 2\n",
    "import models\n",
    "ae = models.autoencoder(image_shape=X.shape[1:])\n",
    "print(ae.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
