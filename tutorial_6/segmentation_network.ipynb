{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"segmentation_network.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"vcB9ZIyVOVkE","colab_type":"text"},"cell_type":"markdown","source":["# Tutorial 6 - Creating a Segmentation U-Net\n","\n","This tutorial follows up on Tutorial 5 from qtim_Tutorials. We will be transforming the network made in that tutorial into a segmentation network, by modifying our preprocessing steps and neural network architecture.\n","\n","# Mounting your Google Drive\n","\n","Running these two blocks of code will give the Colab environment access to your data on Google Drive. If you aren't comfortable with this idea, I'd suggest making a new Drive account dedicated to this project!"]},{"metadata":{"id":"AZSYwExZQ7cq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":107},"outputId":"2a12d33a-3612-4c44-a19f-8247c62e31d2","executionInfo":{"status":"ok","timestamp":1530551685584,"user_tz":240,"elapsed":22832,"user":{"displayName":"A. Beers","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"117153655167770452852"}}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"metadata":{"id":"KL9us_5abXTb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":17},"outputId":"0201bdf8-f328-49d9-9e76-02fa1031447b","executionInfo":{"status":"ok","timestamp":1530551696859,"user_tz":240,"elapsed":2665,"user":{"displayName":"A. Beers","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"117153655167770452852"}}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":12,"outputs":[]},{"metadata":{"id":"6-hXiBgiPTd3","colab_type":"text"},"cell_type":"markdown","source":["Let's navigate to the folder where our data is stored and check everything is there:"]},{"metadata":{"id":"1gGLdcfPbdEz","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"6cef8ec6-9724-4f21-e982-27818463c344","executionInfo":{"status":"ok","timestamp":1530552276968,"user_tz":240,"elapsed":1496,"user":{"displayName":"A. Beers","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"117153655167770452852"}}},"cell_type":"code","source":["import os\n","# !pwd\n","# !ls\n","os.chdir('/content/datalab/drive/Deep_Learning_Class')\n","!ls"],"execution_count":18,"outputs":[{"output_type":"stream","text":["BRATS_10_Updated  colab.ipynb  drive  training.h5  validation.h5\r\n"],"name":"stdout"}]},{"metadata":{"id":"yBHfcvEjDmGX","colab_type":"text"},"cell_type":"markdown","source":["# Installing Prerequisite Packages\n","\n","Some of the code we're running requires other packages to be installed. You can install them to Colab using the following pip install commands. To run a bash command in Colab, prepend it with a \"!\"."]},{"metadata":{"id":"-T8RdI8GCrS3","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!pip install nibabel"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IeHQYyysvn6n","colab_type":"text"},"cell_type":"markdown","source":["# Preprocessing Our Data (again)\n","\n","When we first preprocessed our data, we preprocessed it for the MR slice classification case. This meant that we took ground truth slices and assigned them a \"0\" or \"1\" value depending on whether they contained tumor slices or not. This time, we want to predict segmentations, not classifications, so we're going to omit the binary 0/1 classification step.\n","\n","We've copied below our preprocessing steps from the previous tutorial, and made some modifications for preprocessing in \"segmentation\" mode, as opposed to \"classification\"."]},{"metadata":{"id":"QIhttuCZvqQZ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"ccfdd8f3-4510-4382-a4a1-9f0d63c36b41","executionInfo":{"status":"ok","timestamp":1530553752853,"user_tz":240,"elapsed":277,"user":{"displayName":"A. Beers","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"117153655167770452852"}}},"cell_type":"code","source":["import os\n","import numpy as np\n","import nibabel as nib\n","\n","def load_all_sequences_from_patients(input_directory, patient_id):\n","\n","    output_arrays = []\n","    sequences = ['t1ce', 't1', 'flair', 't2', 'seg']\n","    \n","    for sequence in sequences:\n","        target_file = os.path.join(input_directory, patient_id, patient_id + '_' + sequence + '.nii.gz')\n","        data_array = nib.load(target_file).get_data()\n","        output_arrays.append(data_array)\n","    \n","    stacked_output_array = np.stack(output_arrays[0:4], axis=-1)\n","    ground_truth_array = np.expand_dims(output_arrays[-1], axis=-1)    \n","    return stacked_output_array, ground_truth_array\n","\n","  \n","def split_3d_array_into_2d_slices(input_array, skip=20):\n","    \n","    total_axial_slices = input_array.shape[2]\n","    output_slices = list()\n","    \n","    for current_axial_num in range(skip, total_axial_slices-skip):\n","        \n","        extracted_slice = input_array[:, :, current_axial_num, :]\n","        output_slices.append(extracted_slice)\n","        \n","    return output_slices\n","\n","def assign_ground_truth_from_slices(input_ground_truth_slices):\n","    \n","    ground_truth_labels = list()\n","    \n","    for ground_truth_slice in input_ground_truth_slices:\n","        \n","        if np.sum(ground_truth_slice) > 0:\n","            ground_truth_labels.append(1)\n","        else:\n","            ground_truth_labels.append(0)\n","        \n","    return ground_truth_labels\n","\n","def normalize_images(input_3d_data):\n","        \n","    number_of_channels = input_3d_data.shape[-1]\n","    normalized = []\n","    \n","    for channel in range(number_of_channels):\n","        \n","        extracted_channel = input_3d_data[:, :, :, channel].copy()\n","\n","        masked_channel = np.copy(extracted_channel)\n","        masked_channel[masked_channel == 0] = -100\n","        masked_channel = np.ma.masked_where(masked_channel == -100, masked_channel)\n","\n","        masked_channel = masked_channel - np.mean(masked_channel)\n","        masked_channel = masked_channel / np.std(masked_channel)\n","        \n","        normalized.append(masked_channel.astype('float16'))\n","        \n","    return np.stack(normalized, axis=3)\n","\n","def generate_dataset(data_directory, patient_data_list, mode=\"segmentation\"):\n","\n","    X, y = [], [] \n","\n","    for patient_directory in patient_data_list:\n","\n","        print('Working on...', patient_directory)\n","      \n","        # Load nifti files for MR sequences and tumor segmentation\n","        patient_sequences, ground_truth = load_all_sequences_from_patients(data_directory, patient_directory)\n","\n","        # Normalize input volumes\n","        patient_norm = normalize_images(patient_sequences)  # this is a new addition too\n","\n","        # 4D volumes to slices\n","        sequence_slices = split_3d_array_into_2d_slices(patient_norm)\n","        ground_truth_slices = split_3d_array_into_2d_slices(ground_truth)\n","\n","        # Get ground truth vector\n","        if mode == \"classification\":\n","          ground_truth_vector = assign_ground_truth_from_slices(ground_truth_slices)\n","        elif mode == \"segmentation\":\n","          ground_truth_vector = ground_truth_slices\n","\n","        # Append this patient to our lists\n","        X.append(sequence_slices)\n","        y.append(ground_truth_vector)\n","\n","    X = np.asarray(X)\n","    print(X.shape)\n","    # (1000, 240, 240, 4)\n","    \n","    if mode == \"classification\":\n","        y = np.hstack(y)\n","    elif mode == \"segmentation\":\n","        y = np.array(y)\n","    \n","    # Grab the dimensions of the 5D array\n","    patients, slices, rows, cols, ch = X.shape\n","\n","    # Combine the first two dimension (patients, slices) into one\n","    X = X.reshape(patients*slices, rows, cols, ch)\n","    \n","    if mode == 'segmentation':\n","      patients, slices, rows, cols, ch = y.shape\n","      y = y.reshape(patients * slices, rows, cols, ch)\n","    \n","    return X, y"],"execution_count":34,"outputs":[]},{"metadata":{"id":"ADB4YxeeC0zx","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":225},"outputId":"6632ea5d-fbb0-4785-d18a-a5238e76093a","executionInfo":{"status":"ok","timestamp":1530554174456,"user_tz":240,"elapsed":122679,"user":{"displayName":"A. Beers","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"117153655167770452852"}}},"cell_type":"code","source":["input_directory = 'BRATS_10_Updated'\n","test_patient = 'Brats17_2013_0_1'\n","\n","patient_data_list = os.listdir(input_directory)\n","\n","X, y = generate_dataset(input_directory, patient_data_list, mode='segmentation')"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Working on... Brats17_2013_3_1\n","Working on... Brats17_2013_0_1\n","Working on... Brats17_2013_5_1\n","Working on... Brats17_2013_2_1\n","Working on... Brats17_2013_8_1\n","Working on... Brats17_2013_1_1\n","Working on... Brats17_2013_4_1\n","Working on... Brats17_2013_6_1\n","Working on... Brats17_2013_18_1\n","Working on... Brats17_2013_7_1\n","Working on... Brats17_2013_9_1\n","(11, 115, 240, 240, 4)\n"],"name":"stdout"}]},{"metadata":{"id":"ao9CsADdIclH","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"b1e9c932-16cd-4034-96a5-0d2cce0fadcd","executionInfo":{"status":"ok","timestamp":1530555024610,"user_tz":240,"elapsed":190,"user":{"displayName":"A. Beers","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"117153655167770452852"}}},"cell_type":"code","source":["import h5py  # python package \n","import numpy as np\n","\n","def save_hdf5_file(train_data, ground_truth, output_filename):\n","    \n","    with h5py.File(output_filename, 'w') as file_handle:\n","\n","        file_handle.create_dataset('train', data=train_data, dtype=train_data.dtype)\n","        file_handle.create_dataset('labels', data=ground_truth, dtype=ground_truth.dtype)\n"],"execution_count":50,"outputs":[]},{"metadata":{"id":"hOgKuHhKKQJl","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":69},"outputId":"40ad1b5f-68cb-4906-a06e-278f7ef036a9","executionInfo":{"status":"ok","timestamp":1530555138122,"user_tz":240,"elapsed":108968,"user":{"displayName":"A. Beers","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"117153655167770452852"}}},"cell_type":"code","source":["print('Input data shape', X.shape)\n","print('Ground data shape', y.shape)\n","\n","patients, slices, rows, cols, ch = y.shape\n","y_fixed = y.reshape(patients * slices, rows, cols, ch)\n","\n","print('New Ground truth data shape', y_fixed.shape)\n","\n","output_filename = 'training_segmentation.h5'\n","save_hdf5_file(X, y_fixed, output_filename)"],"execution_count":51,"outputs":[{"output_type":"stream","text":["Input data shape (1265, 240, 240, 4)\n","Ground data shape (11, 115, 240, 240, 1)\n","New Ground truth data shape (1265, 240, 240, 1)\n"],"name":"stdout"}]},{"metadata":{"id":"5SQiDqIwM-H1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":52},"outputId":"a6acb3d7-01ee-49fb-d21c-eb8ad8976701","executionInfo":{"status":"ok","timestamp":1530555275826,"user_tz":240,"elapsed":3571,"user":{"displayName":"A. Beers","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"117153655167770452852"}}},"cell_type":"code","source":["# Check to see if we have our new h5 file.\n","!ls"],"execution_count":52,"outputs":[{"output_type":"stream","text":["BRATS_10_Updated  drive        training_segmentation.h5\r\n","colab.ipynb\t  training.h5  validation.h5\r\n"],"name":"stdout"}]},{"metadata":{"id":"3MSzs_RIPGAd","colab_type":"text"},"cell_type":"markdown","source":["# Implementing our Network (and upgrading it to the full U-Net)"]},{"metadata":{"id":"uRPnbnUtRbrE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":37},"outputId":"36988e83-48a9-49be-9381-6eef1355c03f","executionInfo":{"status":"ok","timestamp":1530556938098,"user_tz":240,"elapsed":217,"user":{"displayName":"A. Beers","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"117153655167770452852"}}},"cell_type":"code","source":["from keras.layers import Input, Conv2D, MaxPool2D, Dense, Dropout, BatchNormalization, Flatten, UpSampling2D, Concatenate\n","from keras.layers.pooling import GlobalAveragePooling2D\n","from keras.models import Model\n","\n","def make_model(max_channels=1024, mode='segmentation'):\n","\n","    # First block\n","    input_layer = Input(shape=(240, 240, 4))\n","    conv1 = Conv2D(max_channels // 16, (3, 3), padding='same', activation='relu')(input_layer)\n","    conv2 = Conv2D(max_channels // 16, (3, 3), padding='same', activation='relu')(conv1)\n","    conv2 = BatchNormalization()(conv2)\n","    pool1 = MaxPool2D((2, 2))(conv2)\n","\n","    # Second block\n","    conv3 = Conv2D(max_channels // 8, (3, 3), padding='same', activation='relu')(pool1)\n","    conv4 = Conv2D(max_channels // 8, (3, 3), padding='same', activation='relu')(conv3)\n","    conv4 = BatchNormalization()(conv4)\n","    pool2 = MaxPool2D((2, 2))(conv4)\n","\n","    # Third block\n","    conv5 = Conv2D(max_channels // 4, (3, 3), padding='same', activation='relu')(pool2)\n","    conv6 = Conv2D(max_channels // 4, (3, 3), padding='same', activation='relu')(conv5)\n","    conv6 = BatchNormalization()(conv6)\n","    pool3 = MaxPool2D((2, 2))(conv6)\n","\n","    # Fourth block\n","    conv7 = Conv2D(max_channels // 2, (3, 3), padding='same', activation='relu')(pool3)\n","    conv8 = Conv2D(max_channels // 2, (3, 3), padding='same', activation='relu')(conv7)\n","    conv8 = BatchNormalization()(conv8)\n","    pool4 = MaxPool2D((2, 2))(conv8)\n","\n","    # Fifth block\n","    conv9 = Conv2D(max_channels, (3, 3), padding='same', activation='relu')(pool4)\n","    conv10 = Conv2D(max_channels, (3, 3), padding='same', activation='relu')(conv9)\n","    conv10 = BatchNormalization()(conv10)\n","\n","    if mode == 'segmentation':\n","        upsample1 = UpSampling2D((2, 2))(conv10)\n","        concatenate1 = Concatenate(axis=-1)([upsample1, conv8])\n","        conv11 = Conv2D(max_channels // 2, (3, 3), padding='same', activation='relu')(concatenate1)\n","\n","\n","    if mode == 'classification':\n","      \n","      # flatten = Flatten()(conv10)\n","      pool5 = GlobalAveragePooling2D()(conv10)\n","\n","      # Fully-connected\n","      dense1 = Dense(128, activation='relu')(flatten)\n","      drop1 = Dropout(0.5)(dense1)\n","      output = Dense(1, activation='sigmoid')(drop1)\n","\n","    # Create model object\n","    model = Model(inputs=input_layer, outputs=conv11)\n","    print(model.summary())\n","    \n","    return model"],"execution_count":68,"outputs":[]},{"metadata":{"id":"reIR0UJoP2mg","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":971},"outputId":"f6862224-6140-4e85-e672-9d258392d576","executionInfo":{"status":"ok","timestamp":1530556945831,"user_tz":240,"elapsed":1176,"user":{"displayName":"A. Beers","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"117153655167770452852"}}},"cell_type":"code","source":["model = make_model(mode='segmentation')"],"execution_count":69,"outputs":[{"output_type":"stream","text":["__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_6 (InputLayer)            (None, 240, 240, 4)  0                                            \n","__________________________________________________________________________________________________\n","conv2d_51 (Conv2D)              (None, 240, 240, 64) 2368        input_6[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_52 (Conv2D)              (None, 240, 240, 64) 36928       conv2d_51[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_26 (BatchNo (None, 240, 240, 64) 256         conv2d_52[0][0]                  \n","__________________________________________________________________________________________________\n","max_pooling2d_21 (MaxPooling2D) (None, 120, 120, 64) 0           batch_normalization_26[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_53 (Conv2D)              (None, 120, 120, 128 73856       max_pooling2d_21[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_54 (Conv2D)              (None, 120, 120, 128 147584      conv2d_53[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_27 (BatchNo (None, 120, 120, 128 512         conv2d_54[0][0]                  \n","__________________________________________________________________________________________________\n","max_pooling2d_22 (MaxPooling2D) (None, 60, 60, 128)  0           batch_normalization_27[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_55 (Conv2D)              (None, 60, 60, 256)  295168      max_pooling2d_22[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_56 (Conv2D)              (None, 60, 60, 256)  590080      conv2d_55[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_28 (BatchNo (None, 60, 60, 256)  1024        conv2d_56[0][0]                  \n","__________________________________________________________________________________________________\n","max_pooling2d_23 (MaxPooling2D) (None, 30, 30, 256)  0           batch_normalization_28[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_57 (Conv2D)              (None, 30, 30, 512)  1180160     max_pooling2d_23[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_58 (Conv2D)              (None, 30, 30, 512)  2359808     conv2d_57[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_29 (BatchNo (None, 30, 30, 512)  2048        conv2d_58[0][0]                  \n","__________________________________________________________________________________________________\n","max_pooling2d_24 (MaxPooling2D) (None, 15, 15, 512)  0           batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_59 (Conv2D)              (None, 15, 15, 1024) 4719616     max_pooling2d_24[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_60 (Conv2D)              (None, 15, 15, 1024) 9438208     conv2d_59[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_30 (BatchNo (None, 15, 15, 1024) 4096        conv2d_60[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_5 (UpSampling2D)  (None, 30, 30, 1024) 0           batch_normalization_30[0][0]     \n","__________________________________________________________________________________________________\n","concatenate_4 (Concatenate)     (None, 30, 30, 1536) 0           up_sampling2d_5[0][0]            \n","                                                                 batch_normalization_29[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_61 (Conv2D)              (None, 30, 30, 512)  7078400     concatenate_4[0][0]              \n","==================================================================================================\n","Total params: 25,930,112\n","Trainable params: 25,926,144\n","Non-trainable params: 3,968\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"}]},{"metadata":{"id":"dhA8Gk6OPizN","colab_type":"text"},"cell_type":"markdown","source":["# Data generators\n","\n","Keras provides powerful tools for iterating over datasets and augmenting them in real-time. In just a few lines of code, we can define a generator that yields random batches of the data (without ever loading all of it into memory) with randomly applied transformations. This serves to diversify the dataset and hopefully make the resulting model more generalizable."]},{"metadata":{"id":"kB_OaNV1xmIr","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import os\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.utils.io_utils import HDF5Matrix\n","seed = 0\n","\n","data_gen_args = dict( \n","    width_shift_range=0.05,\n","    height_shift_range=0.05,\n","    zoom_range=0.2,\n","    channel_shift_range=0.005,\n","    horizontal_flip=True,\n","    vertical_flip=True\n",")\n","\n","print(os.getcwd())\n","\n","# Generator for the training data\n","train_datagen = ImageDataGenerator(**data_gen_args)\n","X_train = HDF5Matrix('/content/drive/Deep_Learning_Class/training.h5', 'train')\n","y_train = HDF5Matrix('/content/drive/Deep_Learning_Class/training.h5', 'labels')\n","train_generator = train_datagen.flow(X_train, y_train, seed=0, batch_size=16)\n","\n","# Generator for the validation data\n","val_datagen = ImageDataGenerator()  # no augmentation! why?\n","X_val = HDF5Matrix('/content/drive/Deep_Learning_Class/validation.h5', 'train')\n","y_val = HDF5Matrix('/content/drive/Deep_Learning_Class/validation.h5', 'labels')\n","val_generator = val_datagen.flow(X_val, y_val, seed=0, batch_size=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Bem-YhYnY8kX","colab_type":"text"},"cell_type":"markdown","source":["# Training the model\n","\n","At long last, we can train our model! The process goes something like this:\n","\n","* Initialize the network randomly, with a certain optimizer, loss function and metric\n","* Grab a random batch of data from the HDF5 file and randomly augment it\n","* Push it through the network, and get the predictions\n","* Calculate the error (loss)\n","* Calculate the partial derivative of the loss function w.r.t. each of the weights + biases, using back-propagation\n","* Update the network's weights in the negative direction of the gradient, multiplied by the learning rate\n","* Repeat until dataset is exhausted\n","* Run the network on the validation data, but *do not* update the network\n","* Repeat until convergence/fixed number of iterations (epochs) reached\n","\n","We specify two 'callbacks' which are run at the end of each epoch:\n","\n","* Model checkpoint: if the validation loss improves, save the model\n","* Early stopping: if we fail to make progress after a certain number of epochs,  stop early\n"]},{"metadata":{"id":"NvevjJNHfVkT","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":228},"outputId":"d6d23292-6129-44fb-93ea-fa8b1e47a130","executionInfo":{"status":"error","timestamp":1529674643043,"user_tz":240,"elapsed":647,"user":{"displayName":"A. Beers","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"117153655167770452852"}}},"cell_type":"code","source":["from keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","mc_cb = ModelCheckpoint('best_model.h5')\n","el_cb = EarlyStopping(patience=5)\n","\n","model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n","history = model.fit_generator(train_generator, epochs=50, shuffle='batch',\n","                    validation_data=val_generator, callbacks=[mc_cb, el_cb])\n","model.save('final_model.h5')"],"execution_count":6,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-4e62457e7054>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sgd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m history = model.fit_generator(train_generator, epochs=50, shuffle='batch',\n\u001b[0m\u001b[1;32m      8\u001b[0m                     validation_data=val_generator, callbacks=[mc_cb, el_cb])\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'final_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_generator' is not defined"]}]},{"metadata":{"id":"Am8yOi33peru","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from keras.models import load_model\n","import numpy as np\n","import h5py\n","\n","model = load_model('best_model.h5')\n","\n","# We will use testing data in future... this is somewhat biased!\n","val_data = h5py.File('validation.h5', 'r')\n","X_val, y_val = val_data['train'], val_data['labels']\n","\n","y_pred = model.predict(X_val)  # get network predictions over entire dataset\n","y_true = np.asarray(y_val)  # using np.asarray explicitly loads the HDF5 data"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zQrybzGoJQpG","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import pandas as pd\n","pd.DataFrame([y_pred.squeeze(), y_true]).T"],"execution_count":0,"outputs":[]},{"metadata":{"id":"I2Q5PGAsH9Dl","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from sklearn.metrics import roc_curve, auc, confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set_style('white')\n","\n","# Confusion matrix, optionally normalized\n","normalize = False\n","cm = confusion_matrix(y_true, np.round(y_pred).astype('bool'))\n","fmt = 'd'  # for displaying the values\n","\n","if normalize:\n","  cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] # optional!\n","  fmt = '.2%'\n","\n","# Use some fancy plotting\n","labels = ['No tumor', 'Tumor']\n","ax = sns.heatmap(cm, annot=True, fmt=fmt, xticklabels=labels, yticklabels=labels, cmap='Blues')\n","plt.xlabel('Predicted label')\n","plt.ylabel('True label')\n","ax.xaxis.set_label_position('top')\n","ax.xaxis.tick_top()\n","plt.savefig('confusion.png', dpi=300)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DHiHApTXLgwW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["fpr, tpr, _ = roc_curve(y_true, y_pred)\n","plt.plot(fpr, tpr, label='AUC: {:.2f}'.format(auc(fpr, tpr)))\n","plt.title('ROC analysis of my first tumor detector')\n","plt.xlabel('1 - Specificity')\n","plt.ylabel('Sensitivity')\n","plt.legend()\n","plt.savefig('roc.png', dpi=300)"],"execution_count":0,"outputs":[]}]}