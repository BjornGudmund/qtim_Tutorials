{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vcB9ZIyVOVkE"
   },
   "source": [
    "# Mounting your Google Drive\n",
    "\n",
    "Running these two blocks of code will give the Colab environment access to your data on Google Drive. If you aren't comfortable with this idea, I'd suggest making a new Drive account dedicated to this project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17747,
     "status": "ok",
     "timestamp": 1528405995359,
     "user": {
      "displayName": "James Brown",
      "photoUrl": "//lh4.googleusercontent.com/-uoFM3PRUlTo/AAAAAAAAAAI/AAAAAAAANoU/bCtDaLz51oY/s50-c-k-no/photo.jpg",
      "userId": "108976389057231134781"
     },
     "user_tz": 240
    },
    "id": "AZSYwExZQ7cq",
    "outputId": "cc799dce-1480-497f-ea58-8d259461ac2e"
   },
   "outputs": [],
   "source": [
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KL9us_5abXTb"
   },
   "outputs": [],
   "source": [
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6-hXiBgiPTd3"
   },
   "source": [
    "Let's navigate to the folder where our data is stored and check everything is there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3014,
     "status": "ok",
     "timestamp": 1528406043676,
     "user": {
      "displayName": "James Brown",
      "photoUrl": "//lh4.googleusercontent.com/-uoFM3PRUlTo/AAAAAAAAAAI/AAAAAAAANoU/bCtDaLz51oY/s50-c-k-no/photo.jpg",
      "userId": "108976389057231134781"
     },
     "user_tz": 240
    },
    "id": "1gGLdcfPbdEz",
    "outputId": "e354f8c5-d298-4f9a-a357-b27467d26d8e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('drive/MGH/Teaching/qtim_Tutorials/tutorial_5/')\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3MSzs_RIPGAd"
   },
   "source": [
    "# Implementing our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1002
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1138,
     "status": "ok",
     "timestamp": 1528410893113,
     "user": {
      "displayName": "James Brown",
      "photoUrl": "//lh4.googleusercontent.com/-uoFM3PRUlTo/AAAAAAAAAAI/AAAAAAAANoU/bCtDaLz51oY/s50-c-k-no/photo.jpg",
      "userId": "108976389057231134781"
     },
     "user_tz": 240
    },
    "id": "uRPnbnUtRbrE",
    "outputId": "917c9189-0a5f-442a-b6d9-557da8c2f706"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPool2D, Dense, Dropout, BatchNormalization\n",
    "from keras.layers.pooling import GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "\n",
    "max_channels = 1024\n",
    "\n",
    "# First block\n",
    "input_layer = Input(shape=(240, 240, 4))\n",
    "conv1 = Conv2D(max_channels // 16, (3, 3), padding='same', activation='relu')(input_layer)\n",
    "conv2 = Conv2D(max_channels // 16, (3, 3), padding='same', activation='relu')(conv1)\n",
    "conv2 = BatchNormalization()(conv2)\n",
    "pool1 = MaxPool2D((2, 2))(conv2)\n",
    "\n",
    "# Second block\n",
    "conv3 = Conv2D(max_channels // 8, (3, 3), padding='same', activation='relu')(pool1)\n",
    "conv4 = Conv2D(max_channels // 8, (3, 3), padding='same', activation='relu')(conv3)\n",
    "conv4 = BatchNormalization()(conv4)\n",
    "pool2 = MaxPool2D((2, 2))(conv4)\n",
    "\n",
    "# Third block\n",
    "conv5 = Conv2D(max_channels // 4, (3, 3), padding='same', activation='relu')(pool2)\n",
    "conv6 = Conv2D(max_channels // 4, (3, 3), padding='same', activation='relu')(conv5)\n",
    "conv6 = BatchNormalization()(conv6)\n",
    "pool3 = MaxPool2D((2, 2))(conv6)\n",
    "\n",
    "# Fourth block\n",
    "conv7 = Conv2D(max_channels // 2, (3, 3), padding='same', activation='relu')(pool3)\n",
    "conv8 = Conv2D(max_channels // 2, (3, 3), padding='same', activation='relu')(conv7)\n",
    "conv8 = BatchNormalization()(conv8)\n",
    "pool4 = MaxPool2D((2, 2))(conv8)\n",
    "\n",
    "# Fifth block\n",
    "conv9 = Conv2D(max_channels, (3, 3), padding='same', activation='relu')(pool4)\n",
    "conv10 = Conv2D(max_channels, (3, 3), padding='same', activation='relu')(conv9)\n",
    "conv10 = BatchNormalization()(conv10)\n",
    "pool5 = GlobalAveragePooling2D()(conv10)\n",
    "\n",
    "# Fully-connected\n",
    "dense1 = Dense(128, activation='relu')(pool5)\n",
    "drop1 = Dropout(0.5)(dense1)\n",
    "output = Dense(1, activation='sigmoid')(drop1)\n",
    "\n",
    "# Create model object\n",
    "model = Model(inputs=input_layer, outputs=output)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dhA8Gk6OPizN"
   },
   "source": [
    "# Data generators\n",
    "\n",
    "Keras provides powerful tools for iterating over datasets and augmenting them in real-time. In just a few lines of code, we can define a generator that yields random batches of the data (without ever loading all of it into memory) with randomly applied transformations. This serves to diversify the dataset and hopefully make the resulting model more generalizable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "kB_OaNV1xmIr"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.io_utils import HDF5Matrix\n",
    "seed = 0\n",
    "\n",
    "data_gen_args = dict( \n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    zoom_range=0.2,\n",
    "    channel_shift_range=0.005,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "# Generator for the training data\n",
    "train_datagen = ImageDataGenerator(**data_gen_args)\n",
    "X_train = HDF5Matrix('training.h5', 'train')\n",
    "y_train = HDF5Matrix('training.h5', 'labels')\n",
    "train_generator = train_datagen.flow(X_train, y_train, seed=0, batch_size=16)\n",
    "\n",
    "# Generator for the validation data\n",
    "val_datagen = ImageDataGenerator()  # no augmentation! why?\n",
    "X_val = HDF5Matrix('validation.h5', 'train')\n",
    "y_val = HDF5Matrix('validation.h5', 'labels')\n",
    "val_generator = val_datagen.flow(X_val, y_val, seed=0, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bem-YhYnY8kX"
   },
   "source": [
    "# Training the model\n",
    "\n",
    "At long last, we can train our model! The process goes something like this:\n",
    "\n",
    "* Initialize the network randomly, with a certain optimizer, loss function and metric\n",
    "* Grab a random batch of data from the HDF5 file and randomly augment it\n",
    "* Push it through the network, and get the predictions\n",
    "* Calculate the error (loss)\n",
    "* Calculate the partial derivative of the loss function w.r.t. each of the weights + biases, using back-propagation\n",
    "* Update the network's weights in the negative direction of the gradient, multiplied by the learning rate\n",
    "* Repeat until dataset is exhausted\n",
    "* Run the network on the validation data, but *do not* update the network\n",
    "* Repeat until convergence/fixed number of iterations (epochs) reached\n",
    "\n",
    "We specify two 'callbacks' which are run at the end of each epoch:\n",
    "\n",
    "* Model checkpoint: if the validation loss improves, save the model\n",
    "* Early stopping: if we fail to make progress after a certain number of epochs,  stop early\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 444978,
     "status": "ok",
     "timestamp": 1528411649588,
     "user": {
      "displayName": "James Brown",
      "photoUrl": "//lh4.googleusercontent.com/-uoFM3PRUlTo/AAAAAAAAAAI/AAAAAAAANoU/bCtDaLz51oY/s50-c-k-no/photo.jpg",
      "userId": "108976389057231134781"
     },
     "user_tz": 240
    },
    "id": "NvevjJNHfVkT",
    "outputId": "06f9d3e2-4672-4693-a704-7a1ca1de1e4b"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "mc_cb = ModelCheckpoint('best_model.h5')\n",
    "el_cb = EarlyStopping(patience=5)\n",
    "\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit_generator(train_generator, epochs=50, shuffle='batch',\n",
    "                    validation_data=val_generator, callbacks=[mc_cb, el_cb])\n",
    "model.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Am8yOi33peru"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "model = load_model('best_model.h5')\n",
    "\n",
    "# We will use testing data in future... this is somewhat biased!\n",
    "val_data = h5py.File('validation.h5', 'r')\n",
    "X_val, y_val = val_data['train'], val_data['labels']\n",
    "\n",
    "y_pred = model.predict(X_val)  # get network predictions over entire dataset\n",
    "y_true = np.asarray(y_val)  # using np.asarray explicitly loads the HDF5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1882
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 263,
     "status": "ok",
     "timestamp": 1528411690123,
     "user": {
      "displayName": "James Brown",
      "photoUrl": "//lh4.googleusercontent.com/-uoFM3PRUlTo/AAAAAAAAAAI/AAAAAAAANoU/bCtDaLz51oY/s50-c-k-no/photo.jpg",
      "userId": "108976389057231134781"
     },
     "user_tz": 240
    },
    "id": "zQrybzGoJQpG",
    "outputId": "a0585e3c-d50e-4ad3-ca05-e35b1b84039f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame([y_pred.squeeze(), y_true]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1189,
     "status": "ok",
     "timestamp": 1528411697359,
     "user": {
      "displayName": "James Brown",
      "photoUrl": "//lh4.googleusercontent.com/-uoFM3PRUlTo/AAAAAAAAAAI/AAAAAAAANoU/bCtDaLz51oY/s50-c-k-no/photo.jpg",
      "userId": "108976389057231134781"
     },
     "user_tz": 240
    },
    "id": "I2Q5PGAsH9Dl",
    "outputId": "c40b3164-0a1a-413e-8559-1bc377f17cf2"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "\n",
    "# Confusion matrix, optionally normalized\n",
    "normalize = False\n",
    "cm = confusion_matrix(y_true, np.round(y_pred).astype('bool'))\n",
    "fmt = 'd'  # for displaying the values\n",
    "\n",
    "if normalize:\n",
    "  cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] # optional!\n",
    "  fmt = '.2%'\n",
    "\n",
    "# Use some fancy plotting\n",
    "labels = ['No tumor', 'Tumor']\n",
    "ax = sns.heatmap(cm, annot=True, fmt=fmt, xticklabels=labels, yticklabels=labels, cmap='Blues')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "ax.xaxis.set_label_position('top')\n",
    "ax.xaxis.tick_top()\n",
    "plt.savefig('confusion.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1069,
     "status": "ok",
     "timestamp": 1528411704928,
     "user": {
      "displayName": "James Brown",
      "photoUrl": "//lh4.googleusercontent.com/-uoFM3PRUlTo/AAAAAAAAAAI/AAAAAAAANoU/bCtDaLz51oY/s50-c-k-no/photo.jpg",
      "userId": "108976389057231134781"
     },
     "user_tz": 240
    },
    "id": "DHiHApTXLgwW",
    "outputId": "8c699473-6edb-4ee4-8780-ea5ebf883266"
   },
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "plt.plot(fpr, tpr, label='AUC: {:.2f}'.format(auc(fpr, tpr)))\n",
    "plt.title('ROC analysis of my first tumor detector')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.legend()\n",
    "plt.savefig('roc.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Tutorial 5C",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
