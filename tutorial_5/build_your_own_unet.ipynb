{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building A U-Net, One Step at a Time\n",
    "\n",
    "Rise and shine! It's time for deep learning.\n",
    "\n",
    "![title](u-net-architecture.png)\n",
    "\n",
    "In today's tutorial, and subsequent classes, we will be building our own deep neural network architecture and putting it to work on a practical problem. Specifically, we will be creating the popular U-Net architecture, which revolutionized many images segmentation tasks. We will be tackling the problem of brain tumor segmentation based off of 2D slices of images. Many if not all of the methods we show in this tutorial can be applied on 3D images, but 2D images are slightly less complex and take less computing power.\n",
    "\n",
    "There are a few intermediate goals we will hit in this tutorial. They are:\n",
    "\n",
    "- Preprocessing 3D MRI data into a collection of intensity normalized, uniformly-sized 2D slices, and splitting them into class-balanced training and testing datasets for training our neural networks.\n",
    "- Constructing the first arm of the U-Net, \"the downsampling arm\", and training it as an image classifier (in our case, contains-tumor or does-not-contain-tumor). This will introduce the basics of home-brewed neural networks without adding some of the more complicated bits that characterize the full U-Net architecture.\n",
    "- Showing how we can generate class-activation maps for our downsampling arm. These maps will show us which parts of an image were most informative in the tumor-no-tumor classification task. We will then use these activation maps as an additional channel during training of the full U-Net\n",
    "- Building the upsampling arm of the U-Net and adding concatenation layers. We will train this new network to segment brain tumors, instead of merely identifying if they are present.\n",
    "\n",
    "Without further ado, let's get started on the data preprocessing.\n",
    "\n",
    "## Preprocessing the Data\n",
    "\n",
    "We will be using the famed BraTS dataset during this tutorial. The BraTS dataset is a collection of scans from a cohort of patients with low-grade and high-grade glioblastoma tumors. For each patient, one visit is presented, with four MRI sequences: T2, pre-contrast T1, post-contrast T1, and FLAIR. Annotations of enhancing tumor, edema, and necrosis are provided for each patient visit, and are generated from the average of multiple radiologists' hand-drawn annotations.\n",
    "\n",
    "![title](BRATS.png)\n",
    "\n",
    "Although much medical data comes in DICOM format, we will be providing the data to you in NIFTI format for this tutorial. In order to load and manipulate NIFTI data, we will need the python package \"nibabel\". Take a moment, if you haven't already, to install nibabel via the pip package installer. This installer should come with most installations of Python."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install nibabel --user  %% Run in command line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step for us is to load a Nifti image, and try and get a sense of the sort of data we're dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\James\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib  # By convention, nibabel is abbreviated to nib, much as numpy is abbreviated to np\n",
    "\n",
    "input_file = 'BRATS_10_Updated/Brats17_2013_18_1/Brats17_2013_18_1_flair.nii.gz'\n",
    "loaded_nifti = nib.load(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy enough! Let's see what we're dealing with here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nibabel.nifti1.Nifti1Image'>\n",
      "data shape (240, 240, 155)\n",
      "affine: \n",
      "[[ -1.   0.   0.  -0.]\n",
      " [  0.  -1.   0. 239.]\n",
      " [  0.   0.   1.   0.]\n",
      " [  0.   0.   0.   1.]]\n",
      "metadata:\n",
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b'r'\n",
      "dim_info        : 0\n",
      "dim             : [  3 240 240 155   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : int16\n",
      "bitpix          : 16\n",
      "slice_start     : 0\n",
      "pixdim          : [1. 1. 1. 1. 0. 0. 0. 0.]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 2\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : b''\n",
      "aux_file        : b''\n",
      "qform_code      : aligned\n",
      "sform_code      : scanner\n",
      "quatern_b       : 0.0\n",
      "quatern_c       : 0.0\n",
      "quatern_d       : 1.0\n",
      "qoffset_x       : -0.0\n",
      "qoffset_y       : 239.0\n",
      "qoffset_z       : 0.0\n",
      "srow_x          : [-1.  0.  0. -0.]\n",
      "srow_y          : [  0.  -1.   0. 239.]\n",
      "srow_z          : [0. 0. 1. 0.]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n"
     ]
    }
   ],
   "source": [
    "print(loaded_nifti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weird. You may have thought you were loading the MRI data into a data array, but instead you were loading data into a nibabel Nifti object. This object contains the data of the MRI scan in numpy format, but also contains extra information about the image stored in the NIFTI file's header. This is what you see printed above. This information can tell you about the resolution of an image (pixdim), the orientation of the patient with respect to the scanner (affine), and other information that may be useful to a medical imaging program (e.g. data-type).\n",
    "\n",
    "When it comes to deep learning in this tutorial, however, we're mostly interested numpy array data that represents this scan. We need a new command to get that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(240, 240, 155)\n"
     ]
    }
   ],
   "source": [
    "scan_array = loaded_nifti.get_data()\n",
    "print(type(scan_array))\n",
    "print(scan_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better -- a numpy array with 512 rows, 512 columns, and 20 axial slices. It's usually a profitable first step to visualize your data, and that's what we're going to try to do now. Let's load up matplotlib and see if we can't take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f5d98e600495>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscan_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'none'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lower'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[0;32m   3203\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3204\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3205\u001b[1;33m                         **kwargs)\n\u001b[0m\u001b[0;32m   3206\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3207\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1853\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1855\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1856\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5485\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    651\u001b[0m         if not (self._A.ndim == 2\n\u001b[0;32m    652\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m--> 653\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Just for Jupyter Notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "im = plt.imshow(scan_array, interpolation='none', origin='lower', cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh -- duh, you can't show a 3D image the same way that you would show a 2D image. Using some of numpy's array slicing features, however, we can look at individual slices in our volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scan_array.shape)\n",
    "total_axial_slices = scan_array.shape[2]\n",
    "\n",
    "for axial_slice_num in range(total_axial_slices):\n",
    "    \n",
    "    print(axial_slice_num)\n",
    "    im = plt.imshow(scan_array[:, :, axial_slice_num], interpolation='none', origin='lower', cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's more like it! Slices from a MRI of a patient with a brain tumor. You'll notice that the brain is not facing the traditional direction when we load in matplotlib. This is because we threw away the patient orientation data with the rest of the NIFTI header, and loaded our array without further transformation. Without knowing how to orient the data, numpy simply displays it as is. For our sanity, let's rotate it the correct direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "total_axial_slices = scan_array.shape[2]\n",
    "\n",
    "for axial_slice_num in range(total_axial_slices):\n",
    "    \n",
    "    # Using numpy, we rotate 90 degrees clockwise 3 times, making the nose point \"up\"\n",
    "    im = plt.imshow(np.rot90(scan_array[:, :, axial_slice_num], 1), interpolation='none', origin='lower', cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better, although it's anyone's guess at this point which direction is right and which direction is left. Let's get the tumor label provided by the clinicians and load that up side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_label = 'BRATS_10_Updated/Brats17_2013_18_1/Brats17_2013_18_1_seg.nii.gz'\n",
    "\n",
    "loaded_label = nib.load(input_label)\n",
    "label_array = loaded_label.get_data()\n",
    "\n",
    "for axial_slice_num in range(total_axial_slices):\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    im = plt.imshow(np.rot90(scan_array[:, :, axial_slice_num], 3), interpolation='none', origin='lower', cmap='gray')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    im = plt.imshow(np.rot90(label_array[:, :, axial_slice_num], 3), interpolation='none', origin='lower', cmap='Dark2')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty cool! You can tell the label overlaps with the tumor. So far, we've just been looking at one sequence, however. Let's try and load up all of the sequences we have for this patient, and maybe do it a bit more a systematic way that we've been working on so far. This will help for later in the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRATS_10_Updated/Brats17_2013_18_1\\Brats17_2013_18_1_t1ce.nii.gz\n",
      "BRATS_10_Updated/Brats17_2013_18_1\\Brats17_2013_18_1_t1.nii.gz\n",
      "BRATS_10_Updated/Brats17_2013_18_1\\Brats17_2013_18_1_flair.nii.gz\n",
      "BRATS_10_Updated/Brats17_2013_18_1\\Brats17_2013_18_1_t2.nii.gz\n",
      "BRATS_10_Updated/Brats17_2013_18_1\\Brats17_2013_18_1_seg.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_directory = 'BRATS_10_Updated/Brats17_2013_18_1'\n",
    "\n",
    "def load_all_sequences_from_patients(input_directory, patient_id):\n",
    "\n",
    "    output_arrays = []\n",
    "    sequences = ['t1ce', 't1', 'flair', 't2', 'seg']\n",
    "    \n",
    "    for sequence in sequences:\n",
    "        target_file = os.path.join(input_directory, patient_id + '_' + sequence + '.nii.gz')\n",
    "        print(target_file)\n",
    "        data_array = nib.load(target_file).get_data()\n",
    "        output_arrays.append(data_array)\n",
    "        \n",
    "        # Alternate Ways to write append\n",
    "        # output_arrays += [data_array]\n",
    "        # output_arrays = output_arrays + [data_array]\n",
    "        \n",
    "    return output_arrays\n",
    "\n",
    "# Alternate\n",
    "# outputs = load_all_sequences_from_patients(data_directory, 'Brats...')\n",
    "# T1POST = outputs[0]\n",
    "# T1PRE = outputs[1]\n",
    "# FLAIR = outputs[2]\n",
    "# etc.\n",
    "\n",
    "T1POST, T1PRE, FLAIR, T2, GROUND_TRUTH = load_all_sequences_from_patients(data_directory, 'Brats17_2013_18_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Let's look at them again using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'total_axial_slices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c93755f6d345>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minput_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_axial_slices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0maxial_slice_num\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_axial_slices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'total_axial_slices' is not defined"
     ]
    }
   ],
   "source": [
    "input_label = ''\n",
    "\n",
    "print(total_axial_slices)\n",
    "\n",
    "for axial_slice_num in range(60, total_axial_slices):\n",
    "\n",
    "    #scan_number = 0\n",
    "    \n",
    "    plt.figure(figsize = (20, 5))\n",
    "    \n",
    "    for scan_number, scan in enumerate([T1POST, T1PRE, FLAIR, T2, GROUND_TRUTH]):\n",
    "        \n",
    "        # Alternate\n",
    "        # scan_number = scan_number + 1\n",
    "    \n",
    "        plt.subplot(1, 5, scan_number + 1)\n",
    "        im = plt.imshow(np.rot90(scan[:, :, axial_slice_num], 1), interpolation='none', origin='lower', cmap='gray')\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the goal becomes clear. Given the four images on the left, we want to produce the tumor segmentation on the right. We'll do that eventually, but for now we'll start with an easier goal. Given a slice of an brain MRI image, can we say whether or not there's a tumor in it. To do that, we'll need to start preprocessing our image. Here's how we'll do that:\n",
    "\n",
    "- Combine our four input images into a single array with four channels\n",
    "- Resize our images to 224x224 shape.\n",
    "- Divide them into 2d slices\n",
    "- Assess each tumor label slice, and create a ground-truth array of either tumor or no-tumor.\n",
    "- Normalize the intensities in our MRI scans to have \"zero mean and unit variance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_all_sequences_from_patients(input_directory, patient_id):\n",
    "\n",
    "    output_arrays = []\n",
    "    sequences = ['t1ce', 't1', 'flair', 't2', 'seg']\n",
    "    \n",
    "    for sequence in sequences:\n",
    "        target_file = os.path.join(input_directory, patient_id, patient_id + '_' + sequence + '.nii.gz')\n",
    "        data_array = nib.load(target_file).get_data()\n",
    "        output_arrays.append(data_array)\n",
    "    \n",
    "    stacked_output_array = np.stack(output_arrays[0:4], axis=-1)\n",
    "    ground_truth_array = np.expand_dims(output_arrays[-1], axis=-1)    \n",
    "    return stacked_output_array, ground_truth_array\n",
    "\n",
    "\n",
    "stacked_sequences, ground_truth = load_all_sequences_from_patients('BRATS_10_Updated', 'Brats17_2013_18_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_3d_array_into_2d_slices(input_array, skip=20):\n",
    "    \n",
    "    total_axial_slices = input_array.shape[2]\n",
    "    output_slices = list()\n",
    "#     print('empty list', output_slices)\n",
    "    \n",
    "    for current_axial_num in range(skip, total_axial_slices-skip):\n",
    "        \n",
    "        extracted_slice = input_array[:, :, current_axial_num, :]\n",
    "        output_slices.append(extracted_slice)\n",
    "        \n",
    "    return output_slices\n",
    "        \n",
    "patient_slices_2d = split_3d_array_into_2d_slices(stacked_sequences)\n",
    "ground_truth_slices_2d = split_3d_array_into_2d_slices(ground_truth)\n",
    "\n",
    "# for patient_slice in patient_slices_2d:\n",
    "#     print(patient_slice.shape, 'input_data')\n",
    "# for patient_slice in ground_truth_slices_2d:\n",
    "#     print(patient_slice.shape, 'ground_truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "def assign_ground_truth_from_slices(input_ground_truth_slices):\n",
    "    \n",
    "    ground_truth_labels = list()\n",
    "    \n",
    "    for ground_truth_slice in input_ground_truth_slices:\n",
    "        \n",
    "        if np.sum(ground_truth_slice) > 0:\n",
    "            ground_truth_labels.append(1)\n",
    "        else:\n",
    "            ground_truth_labels.append(0)\n",
    "        \n",
    "    return ground_truth_labels\n",
    "\n",
    "patient_ground_truth_labels = assign_ground_truth_from_slices(ground_truth_slices_2d)\n",
    "print(patient_ground_truth_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_images(input_3d_data):\n",
    "        \n",
    "    number_of_channels = input_3d_data.shape[-1]\n",
    "    normalized = []\n",
    "    \n",
    "    for channel in range(number_of_channels):\n",
    "        \n",
    "        extracted_channel = input_3d_data[:, :, :, channel].copy()\n",
    "\n",
    "        masked_channel = np.copy(extracted_channel)\n",
    "        masked_channel[masked_channel == 0] = -100\n",
    "        masked_channel = np.ma.masked_where(masked_channel == -100, masked_channel)\n",
    "\n",
    "        masked_channel = masked_channel - np.mean(masked_channel)\n",
    "        masked_channel = masked_channel / np.std(masked_channel)\n",
    "        \n",
    "        normalized.append(masked_channel.astype('float16'))\n",
    "        \n",
    "    return np.stack(normalized, axis=3)\n",
    "\n",
    "normalized_stacked_sequences = normalize_images(stacked_sequences)\n",
    "\n",
    "# for patient_slice in patient_slices_2d:\n",
    "#     for channel in range(patient_slice.shape[-1]):\n",
    "#         print(channel, 'channel_number')\n",
    "#         print(np.mean(patient_slice[:, :, channel]), np.std(patient_slice[:, :, channel]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "\n",
    "We wrote several functions to maximize reusability:\n",
    "\n",
    "* `load_all_sequences_from_patients` - loads all sequences for a particular patient\n",
    "* `split_3d_array_into_2d_slices` - split a single nifti volume into 2D slices\n",
    "* `assign_ground_truth_from_slices` - creates a list of zeros and ones representing 'tumor' or 'no tumor' for each slice\n",
    "* `normalize_images` - normalizes a volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py  # python package \n",
    "import numpy as np\n",
    "# samples, rows, columns, channels\n",
    "# n, 240, 240, 4\n",
    "\n",
    "# samples, 1\n",
    "# 0, 0, 0, 1, 1, ..., 0\n",
    "\n",
    "def save_hdf5_file(train_data, ground_truth, output_filename):\n",
    "    \n",
    "    with h5py.File(output_filename, 'w') as file_handle:\n",
    "\n",
    "        file_handle.create_dataset('train', data=train_data, dtype=train_data.dtype)\n",
    "        file_handle.create_dataset('labels', data=ground_truth, dtype=ground_truth.dtype)\n",
    "\n",
    "# Generate fake data\n",
    "X = np.zeros(shape=[10, 240, 240, 4])\n",
    "y = np.zeros(shape=(10, 1))\n",
    "save_hdf5_file(X, y, 'fake_data.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code was updated outside of the tutorial, so that we can process subsets of the data more easily\n",
    "import os\n",
    "\n",
    "def generate_dataset(patient_data_list):\n",
    "\n",
    "    X, y = [], [] \n",
    "\n",
    "    for patient_directory in patient_data_list:\n",
    "\n",
    "        # Load nifti files for MR sequences and tumor segmentation\n",
    "        patient_sequences, ground_truth = load_all_sequences_from_patients(data_directory, patient_directory)\n",
    "\n",
    "        # Normalize input volumes\n",
    "        patient_norm = normalize_images(patient_sequences)  # this is a new addition too\n",
    "\n",
    "        # 4D volumes to slices\n",
    "        sequence_slices = split_3d_array_into_2d_slices(patient_norm)\n",
    "        ground_truth_slices = split_3d_array_into_2d_slices(ground_truth)\n",
    "\n",
    "        # Get ground truth vector\n",
    "        ground_truth_vector = assign_ground_truth_from_slices(ground_truth_slices)\n",
    "\n",
    "        # Append this patient to our lists\n",
    "        X.append(sequence_slices)\n",
    "        y.append(ground_truth_vector)\n",
    "\n",
    "    X = np.asarray(X)\n",
    "    y = np.hstack(y)\n",
    "\n",
    "    # Grab the dimensions of the 5D array\n",
    "    patients, slices, rows, cols, ch = X.shape\n",
    "\n",
    "    # Combine the first two dimension (patients, slices) into one\n",
    "    X = X.reshape(patients*slices, rows, cols, ch)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = 'BRATS_10_Updated'\n",
    "all_patients = os.listdir(data_directory)\n",
    "\n",
    "X_train, y_train = generate_dataset(all_patients[:8])\n",
    "X_val, y_val = generate_dataset(all_patients[8:])\n",
    "\n",
    "save_hdf5_file(X_train, y_train, 'training.h5')\n",
    "save_hdf5_file(X_val, y_val, 'validation.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install tensorflow / pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a U-net\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPool2D\n",
    "from keras.models import Model\n",
    "\n",
    "# First block\n",
    "input_layer = Input(shape=(240, 240, 4))\n",
    "conv1 = Conv2D(64, (3, 3), padding='same', activation='relu')(input_layer)\n",
    "conv2 = Conv2D(64, (3, 3), padding='same', activation='relu')(conv1)\n",
    "pool1 = MaxPool2D((2, 2))(conv2)\n",
    "\n",
    "# Second block\n",
    "\n",
    "downsampling_arm = Model(inputs=input_layer, outputs=pool1)\n",
    "print(downsampling_arm.summary())\n",
    "\n",
    "# To be continued..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
